{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to computational biology, MIM UW 2018-19\n",
    "Notes from 1st lecture and lab, including assignments.\n",
    "\n",
    "Â© Krzysztof Kowalczyk kk385830@students.mimuw.edu.pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100    89  100    89    0     0     89      0  0:00:01 --:--:--  0:00:01  5562\n"
     ]
    }
   ],
   "source": [
    "!curl http://regulomics.mimuw.edu.pl/wp/wp-content/uploads/2018/02/test_fasta.txt -o data/test_fasta.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might need to install these packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.12\n",
      "  latest version: 4.6.7\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -y biopython tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: suffix-trees in c:\\users\\kkowa\\miniconda3\\envs\\wbo\\lib\\site-packages (0.2.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests suffix-trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, a kernel reload might be necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio\n",
    "from Bio import Seq, SeqIO\n",
    "from suffix_trees import STree\n",
    "from tqdm import tqdm\n",
    "\n",
    "from copy import deepcopy\n",
    "from itertools import product\n",
    "from typing import List, Set, Dict, Tuple, NamedTuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using BioPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq('ATCG')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Seq.Seq(\"ATCG\")\n",
    "s  # object representing a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq('CGAT')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.reverse_complement()  # complementing DNA sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# we can use generator expressions and streaming for efficient data processing\n",
    "seq_in = SeqIO.parse(open('data/test_fasta.txt', 'r'), format='fasta')\n",
    "seq_out = (record.reverse_complement() for record in seq_in)\n",
    "SeqIO.write(seq_out, 'data/test_fasta_complements.txt', format='fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2\n",
    "Generate list of k-mers from a given sequence.\n",
    "\n",
    "This will allow us to transform a known sequence of DNA into a list of k-mers,\n",
    "similar to a one we might get by examining a sample using microarray.\n",
    "\n",
    "We will later use this to test different algorithms of assembling the DNA sequence from its k-mers,\n",
    "having the sequences themselves will allow us to test these algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_test = Seq.Seq(\"CATGCAGGTCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmers(s: Bio.Seq.Seq, k: int, complement: bool=False):\n",
    "    \"\"\" Splits a sequence into k-mers, includes complements if necessary \"\"\"\n",
    "    if complement:\n",
    "        # not sure this is the right interpretation of the assignment\n",
    "        seq = s + s.reverse_complement()\n",
    "    else:\n",
    "        seq = s\n",
    "    for i in range(len(seq)-k+1):\n",
    "        yield seq[i:i+k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Seq('CA'),\n",
       " Seq('AT'),\n",
       " Seq('TG'),\n",
       " Seq('GC'),\n",
       " Seq('CA'),\n",
       " Seq('AG'),\n",
       " Seq('GG'),\n",
       " Seq('GT'),\n",
       " Seq('TC'),\n",
       " Seq('CC')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(kmers(s_test, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Seq('CA'),\n",
       " Seq('AT'),\n",
       " Seq('TG'),\n",
       " Seq('GC'),\n",
       " Seq('CA'),\n",
       " Seq('AG'),\n",
       " Seq('GG'),\n",
       " Seq('GT'),\n",
       " Seq('TC'),\n",
       " Seq('CC'),\n",
       " Seq('CG'),\n",
       " Seq('GG'),\n",
       " Seq('GA'),\n",
       " Seq('AC'),\n",
       " Seq('CC'),\n",
       " Seq('CT'),\n",
       " Seq('TG'),\n",
       " Seq('GC'),\n",
       " Seq('CA'),\n",
       " Seq('AT'),\n",
       " Seq('TG')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(kmers(s_test, 2, complement=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3\n",
    "Knowing what k-mers are present in a sequence, we want to determin what the sequence is.\n",
    "\n",
    "Solving this problem is equivalent to finding an hamiltonian path in a graph, \n",
    "which consists of k-mers (nodes) an possible continuations (edges).\n",
    "For example, given k-mers \"AGC\" and \"GCT\" we create an edge from \"AGC\" to \"GCT\" \n",
    "because \"GCT\" can be a continuation of a sequence that starts with \"AGC\"\n",
    "\n",
    "Formally, we will create a directed edge from node n1 to n2, both representing k-mers, \n",
    "if (k-1)-suffix of k-mer represented by n1 is the same as (k-1)-prefix represented by the node n2.\n",
    "\n",
    "After building this graph, the DNA sequence we want to decode is equivalent to the hamiltonian path in this graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Edge = Tuple[int, int]\n",
    "\n",
    "class Graph(NamedTuple):\n",
    "    nodes: List[Bio.Seq.Seq]\n",
    "    edges: Dict[int, Set[Edge]]  # node -> set of adjacent nodes\n",
    "\n",
    "def build_graph(kmers: List[Bio.Seq.Seq]) -> Set[Tuple[int, int]]:\n",
    "    edges = dict()\n",
    "    for idx1, node1 in enumerate(kmers):\n",
    "        for idx2, node2 in enumerate(kmers):\n",
    "            if node1[1:] == node2[:-1]:\n",
    "                edge = (idx1, idx2)\n",
    "                try:\n",
    "                    edges[idx1].add(edge)\n",
    "                except KeyError:\n",
    "                    edges[idx1] = {edge}\n",
    "    return Graph(kmers, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(nodes=[Seq('CAT'), Seq('ATG'), Seq('TGC'), Seq('GCA'), Seq('CAG'), Seq('AGG'), Seq('GGT'), Seq('GTC'), Seq('TCC')], edges={0: {(0, 1)}, 1: {(1, 2)}, 2: {(2, 3)}, 3: {(3, 0), (3, 4)}, 4: {(4, 5)}, 5: {(5, 6)}, 6: {(6, 7)}, 7: {(7, 8)}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_3 = list(kmers(s_test, 3))\n",
    "build_graph(test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs(node: int, g: Graph, is_in_stack: List[bool], in_stack_count: int=1, path=[]) -> Tuple[bool, List[Edge]]:\n",
    "    \"\"\"\n",
    "    We can use DFS algorithm to find a hamiltonian path, starting from the specified node.\n",
    "    A node will be labelled \"IN STACK\" if it was visited, but some of its adjacent nodes were not yet visited.\n",
    "    If we manage to visit all nodes, it means we must have traversed the entire hamiltonian path.\n",
    "    \"\"\"\n",
    "    if in_stack_count == len(g.nodes):\n",
    "        return True, path\n",
    "    for edge in g.edges.get(node, {}):\n",
    "        adjacent_node = edge[1]\n",
    "        if is_in_stack[adjacent_node]:\n",
    "            continue\n",
    "        is_in_stack[adjacent_node] = True\n",
    "        path.append(edge)\n",
    "        complete, rec_path = dfs(adjacent_node, g, is_in_stack, in_stack_count+1, path)\n",
    "        if complete:\n",
    "            return True, rec_path\n",
    "        else:\n",
    "            is_in_stack[adjacent_node] = False\n",
    "    return False, []\n",
    "\n",
    "def hamiltonian(g: Graph, starting_node: int=0) -> List[Edge]:\n",
    "    \"\"\" Wrapper for hamiltonian path finding DFS, starting from the specified node. \"\"\"\n",
    "    starting_stack = [False for _ in range(len(g.nodes))]\n",
    "    starting_stack[starting_node] = True\n",
    "    complete, rec_path = dfs(starting_node, g, starting_stack)\n",
    "    if not complete:\n",
    "        raise Exception(\"Graph does not have a hamiltonian path starting from the this node!\")\n",
    "    return rec_path\n",
    "\n",
    "def as_sequence(g: Graph, path: List[Edge]) -> Bio.Seq.Seq:\n",
    "    \"\"\" Assembles a path in a graph into a BioPython DNA sequence. \"\"\"\n",
    "    seq = g.nodes[path[0][0]]  # entire k-mer from starting node\n",
    "    for edge in path:\n",
    "        following_node = g.nodes[edge[1]]\n",
    "        suffix = following_node[-1]\n",
    "        seq += suffix  # append last item of each of the following nodes\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8)] CATGCAGGTCC\n"
     ]
    }
   ],
   "source": [
    "graph = build_graph(test_3)\n",
    "path_h = hamiltonian(graph)\n",
    "result = as_sequence(graph, path_h)\n",
    "print(path_h, result)\n",
    "assert(s_test == result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the implemented scenario, we assume that we know which node is the first one.\n",
    "However, if that assumption cannot be made, the problem requires running DFS algorithm \n",
    "from each of the nodes in graph, as the hamiltonian path problem is NP-complete.\n",
    "\n",
    "Instead, we can use a simple trick to find the path by constructing another graph:\n",
    "\n",
    "Given a graph such as defined above, we can transform it in a following way:\n",
    "1. Use all (k-1)-prefixes and (k-1)-suffixes of each node in a graph as nodes\n",
    "2. For each such prefix and suffix, w1 and w2, create an edge w1 --> w2\n",
    "\n",
    "In such a graph, each original k-mer is repressented by an edge between its prefix and suffix.\n",
    "Therefore, finding an eulerian path in the new graph is equivalent to finding a hamiltonian path in the base graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_eulerian_graph(kmers: List[Bio.Seq.Seq]):\n",
    "    edges = dict()\n",
    "    nodes = list()\n",
    "    for seq in kmers:\n",
    "        n1, n2 = seq[:-1], seq[1:]\n",
    "        try:\n",
    "            i1 = nodes.index(n1)\n",
    "        except ValueError:\n",
    "            nodes.append(n1)\n",
    "            i1 = len(nodes)-1\n",
    "        try:\n",
    "            i2 = nodes.index(n2)\n",
    "        except ValueError:\n",
    "            nodes.append(n2)\n",
    "            i2 = len(nodes)-1\n",
    "        edge = (i1, i2)\n",
    "        try:\n",
    "            edges[i1].add(edge)\n",
    "        except KeyError:\n",
    "            edges[i1] = {edge}\n",
    "    return Graph(nodes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eulerian(g: Graph, starting_node: int=0) -> List[Edge]:\n",
    "    \"\"\" Hierholzer's algorithm for finding eulerian path from a given starting node. \"\"\"\n",
    "    adj = deepcopy(g.edges)  # we need a mutable copy\n",
    "    edge_count = {\n",
    "        i: len(adj.get(i, {})) \n",
    "        for i in range(len(g.nodes))\n",
    "    }\n",
    "    stack = [starting_node]\n",
    "    eulerian_path = []\n",
    "    current_node = starting_node\n",
    "    while len(stack) > 0:\n",
    "        if edge_count[current_node] == 0:\n",
    "            eulerian_path.append(current_node)\n",
    "            current_node = stack.pop()\n",
    "        else:\n",
    "            stack.append(current_node)\n",
    "            next_node = adj[current_node].pop()[1]\n",
    "            edge_count[current_node] -= 1\n",
    "            current_node = next_node\n",
    "    # transform path to desired output format\n",
    "    eulerian_path.reverse()\n",
    "    path_edges = [(i1, i2) for i1, i2 in zip(eulerian_path, eulerian_path[1:])]\n",
    "    return path_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 2), (2, 3), (3, 0), (0, 4), (4, 5), (5, 6), (6, 7), (7, 8)] CATGCAGGTCC\n"
     ]
    }
   ],
   "source": [
    "graph = build_eulerian_graph(test_3)\n",
    "path = eulerian(graph)\n",
    "result = as_sequence(graph, path)\n",
    "print(path, result)\n",
    "assert(s_test == result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home assignment\n",
    "\n",
    "Given a collection of DNA sequences, we want to find a minimal k such that \n",
    "there exists a set of probes of length k in which each probe is complementary to exactly one sequence.\n",
    "\n",
    "This can be accomplished by finding length of maximum common subsequence in the set of sequences.\n",
    "To do this, we only need to compute the pairwise maximum common subsequence for all pairs of sequences,\n",
    "which can be done efficiently by using suffix trees.\n",
    "Maximum common subsequence is the maximum over pairwise longest common subsequences,\n",
    "and the final result is always equal to (maximum common subsequence + 1).\n",
    "\n",
    "This way, we get an efficient $O(n^2\\cdot l^2)$ algorithm, where $l$ is the maximum sequence length and $n$ is the number of sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "input_file = './data/yeast.fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('http://regulomics.mimuw.edu.pl/wp/wp-content/uploads/2018/02/yeast.fa_1.gz', stream=True)\n",
    "if r.status_code == 200:\n",
    "    with open(input_file, 'wb') as f:\n",
    "        r.raw.decode_content = True  # just in case transport encoding was applied\n",
    "        gzip_file = gzip.GzipFile(fileobj=r.raw)\n",
    "        shutil.copyfileobj(gzip_file, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some quick exploration to see what we're dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14733, 702, 1818.8093306288033, 4437)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "io = SeqIO.parse(input_file, format='fasta')\n",
    "record_lengths = [len(record.seq) for record in io]\n",
    "max(record_lengths), min(record_lengths), sum(record_lengths)/len(record_lengths), len(record_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: YPR161C\n",
      "Name: YPR161C\n",
      "Description: YPR161C <unknown description>\n",
      "Number of features: 0\n",
      "Seq('ATGAGTGATAATGGTTCCCCCGCGGTTCTTCCAAAAACCGAATTTAATAAATAC...TAG', SingleLetterAlphabet())\n"
     ]
    }
   ],
   "source": [
    "for record in SeqIO.parse(input_file, format='fasta'):\n",
    "    print(record)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_unique_complementary_length(record_generator, n_records=len(record_lengths)) -> int:\n",
    "    pairs = ((str(a.seq),str(b.seq)) for a,b in product(SeqIO.parse(input_file, format='fasta'), repeat=2) if str(a.seq) < str(b.seq))\n",
    "    pairwise_lcs = (STree.STree(list(pair)).lcs() for pair in tqdm(pairs, total=n_records*(n_records-1)//2))\n",
    "    return max(pairwise_lcs) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "min_unique_complementary_length(SeqIO.parse(input_file, format='fasta'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes >300 minutes, too long to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative approach\n",
    "\n",
    "Binary search for k, checking whether there is a unique k-subsequence for each of the sequences.\n",
    "(does not work yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Instead of comparing a subsequence with each previous subsequences,\n",
    "# we need to remember mapping sequence -> subsequences\n",
    "# and check whether there exists a system of unique representations\n",
    "# for the collection of sequences\n",
    "\n",
    "def min_unique_compl_len(record_generator) -> int:\n",
    "    sequences = list(map(lambda rec: str(rec.seq), record_generator))\n",
    "    max_record_len = max(map(len, sequences))\n",
    "    kmin, kmax = 1, max_record_len+1\n",
    "    while kmin < kmax:  # binary search for minimal k\n",
    "        k = (kmin + kmax)//2\n",
    "        substrings = set()\n",
    "        unique = True\n",
    "        for si, seq in enumerate(sequences):\n",
    "            seq_substrings = set()\n",
    "            for i in range(len(seq)-k):\n",
    "                substring = seq[i:i+k]\n",
    "                seq_substrings.add(substring)\n",
    "            # seq_substrings contains unique k-substrings of seq\n",
    "            # substrings contains unique k-substrings from all previous seqs\n",
    "            if seq_substrings.isdisjoint(substrings):\n",
    "                substrings |= seq_substrings\n",
    "            else:\n",
    "                unique = False\n",
    "                break\n",
    "        print(k, unique)  # progress checking\n",
    "        if unique:\n",
    "            kmax = k\n",
    "        else:\n",
    "            kmin = k + 1\n",
    "    assert(kmin == kmax)\n",
    "    return kmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7367 True\n",
      "3684 False\n",
      "5526 True\n",
      "4605 True\n",
      "4145 False\n",
      "4375 False\n",
      "4490 False\n",
      "4548 True\n",
      "4519 False\n",
      "4534 False\n",
      "4541 False\n",
      "4545 False\n",
      "4547 True\n",
      "4546 False\n",
      "Wall time: 21.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k = min_unique_compl_len(SeqIO.parse(input_file, format='fasta'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
